{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "919963a9-87e5-46b7-aa86-35c477d83f90",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982a27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4403c39",
   "metadata": {},
   "source": [
    "## 1. Configuração\n",
    "\n",
    "- `PDF_PATH`: caminho do seu PDF\n",
    "- `CHUNK_SIZE`: tamanho aproximado do chunk em caracteres (simples e eficiente)\n",
    "- `CHUNK_OVERLAP`: overlap em caracteres\n",
    "- `MODEL_NAME`: modelo de embeddings (padrão: `all-MiniLM-L6-v2`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54ebc4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"./dd-5e-livro-do-jogador-fundo-branco-biblioteca-elfica.pdf\"  \n",
    "OUT_DIR = \"faiss_store\"\n",
    "\n",
    "CHUNK_SIZE = 512\n",
    "CHUNK_OVERLAP = 51\n",
    "\n",
    "MODEL_NAME = \"alfaneo/bertimbau-base-portuguese-sts\" \n",
    "\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2b4cb",
   "metadata": {},
   "source": [
    "## 2) Leitura do PDF e extração de texto\n",
    "\n",
    "A extração é feita por página. Guardamos também o número da página para metadados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f82adf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020647115fad481582fc0ed1c9559777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_pdf_by_page(pdf_path: str) -> List[Dict[str, Any]]:\n",
    "    pdf_path = str(pdf_path)\n",
    "    reader = PdfReader(pdf_path)\n",
    "    pages = []\n",
    "    for i, page in tqdm(enumerate(reader.pages)):\n",
    "        txt = page.extract_text() or \"\"\n",
    "        if txt:\n",
    "            pages.append({\"page\": i + 1, \"text\": txt})\n",
    "    return pages\n",
    "\n",
    "pages = read_pdf_by_page(PDF_PATH)\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e469e",
   "metadata": {},
   "source": [
    "## 3) Chunking (separador de chunks)\n",
    "\n",
    "Este splitter é simples: junta páginas e corta por caracteres com overlap.\n",
    "Se você preferir splitter por tokens, dá para trocar depois.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bce081e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3027"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chunk_text(pages: List[Dict[str, Any]], chunk_size: int, overlap: int) -> List[Dict[str, Any]]:\n",
    "    chunks = []\n",
    "    for p in pages:\n",
    "        text = p[\"text\"]\n",
    "        start = 0\n",
    "        n = len(text)\n",
    "        while start < n:\n",
    "            end = min(start + chunk_size, n)\n",
    "            chunk = text[start:end].strip()\n",
    "            if chunk:\n",
    "                chunks.append({\n",
    "                    \"page\": p[\"page\"],\n",
    "                    \"start_char\": start,\n",
    "                    \"end_char\": end,\n",
    "                    \"text\": chunk\n",
    "                })\n",
    "            if end == n:\n",
    "                break\n",
    "            start = max(0, end - overlap)\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(pages, CHUNK_SIZE, CHUNK_OVERLAP)\n",
    "len(chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb57af",
   "metadata": {},
   "source": [
    "## 4) Embeddings\n",
    "\n",
    "Geramos embeddings para cada chunk.\n",
    "- Usaremos **cosine similarity** (IndexFlatIP) com vetores normalizados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "570961f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159b875042354c96937d2b6a2b819957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: alfaneo/bertimbau-base-portuguese-sts\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60432c2703440aabcff8cda18d632ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((3027, 768), dtype('float32'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "emb = model.encode(\n",
    "    texts,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True, \n",
    ").astype(\"float32\")\n",
    "\n",
    "emb.shape, emb.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35747fc",
   "metadata": {},
   "source": [
    "## 5) Criar FAISS index (CPU) e persistir\n",
    "\n",
    "Salvaremos:\n",
    "- `index.faiss` (vetores)\n",
    "- `meta.jsonl` (metadados por linha, com o mesmo id do vetor)\n",
    "- `config.json` (configs úteis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8a9ad5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3027"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = emb.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)  # inner product (com vetores normalizados => cosine)\n",
    "index.add(emb)\n",
    "\n",
    "index.ntotal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed8e55b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('faiss_store/index.faiss',\n",
       " 'faiss_store/meta.jsonl',\n",
       " 'faiss_store/config.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persistência\n",
    "index_path = str(Path(OUT_DIR) / \"index.faiss\")\n",
    "meta_path = str(Path(OUT_DIR) / \"meta.jsonl\")\n",
    "cfg_path = str(Path(OUT_DIR) / \"config.json\")\n",
    "\n",
    "faiss.write_index(index, index_path)\n",
    "\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, c in enumerate(chunks):\n",
    "        rec = {\n",
    "            \"id\": i,\n",
    "            \"page\": c[\"page\"],\n",
    "            \"start_char\": c[\"start_char\"],\n",
    "            \"end_char\": c[\"end_char\"],\n",
    "            \"text\": c[\"text\"],\n",
    "        }\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "with open(cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"pdf_path\": PDF_PATH,\n",
    "        \"chunk_size\": CHUNK_SIZE,\n",
    "        \"chunk_overlap\": CHUNK_OVERLAP,\n",
    "        \"model_name\": MODEL_NAME,\n",
    "        \"dim\": dim,\n",
    "        \"faiss_index\": \"IndexFlatIP (cosine via normalized embeddings)\",\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "(index_path, meta_path, cfg_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263ef53",
   "metadata": {},
   "source": [
    "## 6) Busca / Recuperação (RAG básico)\n",
    "\n",
    "Funções para:\n",
    "- carregar index e metadados\n",
    "- consultar por `query` e retornar top-k chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b96b20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta(meta_jsonl: str) -> List[Dict[str, Any]]:\n",
    "    items = []\n",
    "    with open(meta_jsonl, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            items.append(json.loads(line))\n",
    "    return items\n",
    "\n",
    "def load_store(out_dir: str):\n",
    "    out_dir = Path(out_dir)\n",
    "    idx = faiss.read_index(str(out_dir / \"index.faiss\"))\n",
    "    meta = load_meta(str(out_dir / \"meta.jsonl\"))\n",
    "    return idx, meta\n",
    "\n",
    "def search(query: str, top_k: int = 5, out_dir: str = OUT_DIR):\n",
    "    idx, meta = load_store(out_dir)\n",
    "    q_emb = model.encode([query], normalize_embeddings=True, convert_to_numpy=True).astype(\"float32\")\n",
    "    scores, ids = idx.search(q_emb, top_k)\n",
    "    results = []\n",
    "    for score, _id in zip(scores[0], ids[0]):\n",
    "        if _id == -1:\n",
    "            continue\n",
    "        m = meta[int(_id)]\n",
    "        results.append({\n",
    "            \"score\": float(score),\n",
    "            \"id\": int(_id),\n",
    "            \"page\": m[\"page\"],\n",
    "            \"text\": m[\"text\"],\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "883a42a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6521 | Page: 74\n",
      ", ignorando \n",
      "barreiras políticas. Todos os druidas são nominalmente \n",
      "membros de uma sociedade druídica, apesar de alguns \n",
      "indivíduos serem tão isolados que eles nunca chegaram a \n",
      "ver membros de alta patente da sociedade ou \n",
      "participaram de encontros druídicos. Os druidas \n",
      "consideram-se irmãos e irmãs. Como criaturas na \n",
      "natureza, no entanto, os druidas, as vezes, competem, ou \n",
      "mesmo caçam uns aos outros. \n",
      "Em uma escala local, os druidas são organizados em \n",
      "círculos que partilham de certas perspectivas de \n",
      "n\n",
      "---\n",
      "\n",
      "Score: 0.6056 | Page: 136\n",
      "nado por cerveja, vinho e outras \n",
      "bebidas. \n",
      "2 Não existe lugar para precaução em uma vida vivida ao \n",
      "máximo. \n",
      "3 Eu lembro de cada insulto que sofri e nutro um \n",
      "ressentimento silencioso contra qualquer um que já tenha \n",
      "me insultado \n",
      "4 Eu tenho dificuldade em confiar em membros de outras \n",
      "raças, tribos ou sociedades. \n",
      "5 A violência é minha resposta para quase todos os \n",
      "obstáculos. \n",
      "6 Não espere que eu salve aqueles que não conseguem se \n",
      "virar sozinhos. É a lei da natureza que os fortes \n",
      "prosperem e os fracos\n",
      "---\n",
      "\n",
      "Score: 0.6004 | Page: 75\n",
      "de \n",
      "druida. Em uma falha, a criatura deve escolher um alvo \n",
      "diferente ou o ataque erra automaticamente. Em um \n",
      "sucesso, a criatura se torna imune a esse efeito por 24 \n",
      "horas. \n",
      "A criatura está ciente deste efeito antes de resolver \n",
      "atacar você. \n",
      "CÍRCULO DA LUA\n",
      "Os druidas do Círculo da Lua são ferrenhos guardiões na \n",
      "natureza. Sua ordem se reuni nas noites de lua cheia \n",
      "para partilhar notícias e trocar informações. Eles \n",
      "assombram as partes mais profundas das florestas, onde \n",
      "eles podia ir por semanas a fio a\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = search(\"O que e um druida?\", top_k=3)\n",
    "for r in results:\n",
    "    print(f\"Score: {r['score']:.4f} | Page: {r['page']}\\n{r['text']}\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6883a51-e97d-4e5a-aac5-2504d0bcbabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
